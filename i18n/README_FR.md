<div align="center">
  <img src="../docs/fr.jpg" alt="French" width="25%" />
</div>

---

# ğŸ§  Plan 3 Mois â€” Passage au Niveau IA avec Python

> ğŸ¯ Objectif : MaÃ®triser le machine learning, le deep learning et les modÃ¨les transformers en Python, avec projets pratiques et dÃ©ploiement.

---

## ğŸ—“ï¸ Mois 1 â€” Fondations IA + Python Data

### ğŸ“Œ Semaine 1 â€“ Python IA & Numpy
- ğŸ”— Cours : [Kaggle Python](https://www.kaggle.com/learn/python) + [Kaggle Numpy](https://www.kaggle.com/learn/numpy)
- âš™ï¸ Setup : installer **Miniconda**, crÃ©er un env `ia`
- ğŸ§ª Projet : script dâ€™analyse matricielle (moyenne, mÃ©diane, Ã©cart-type, etc.)

---

### ğŸ“Œ Semaine 2 â€“ Pandas & Visualisation
- ğŸ”— Cours : [Kaggle Pandas](https://www.kaggle.com/learn/pandas), [Kaggle Data Visualization](https://www.kaggle.com/learn/data-visualization)
- ğŸ§ª Projet : Analyse exploratoire du dataset Titanic (EDA)

---

### ğŸ“Œ Semaine 3 â€“ Machine Learning avec Scikit-learn
- ğŸ”— Cours : [Intro to Machine Learning â€“ Kaggle](https://www.kaggle.com/learn/intro-to-machine-learning)
- ğŸ§ª Projet : PrÃ©dire des prix immo ou classifier des e-mails spam/ham

---

### ğŸ“Œ Semaine 4 â€“ Jupyter + Orga projet
- ğŸ§ª Objectif : maÃ®triser Jupyter, organiser ton code en `.py`, crÃ©er structure projet ML
- Bonus : initier `wandb` ou `mlflow` pour log dâ€™expÃ©riences

---

## ğŸ—“ï¸ Mois 2 â€” Deep Learning avec PyTorch

### ğŸ“Œ Semaine 5 â€“ Bases du Deep Learning
- ğŸ”— Cours : [Deep Learning â€“ Kaggle](https://www.kaggle.com/learn/deep-learning)
- ğŸ§ª Projet : rÃ©seau de neurones "from scratch" en `numpy` (rÃ©gression XOR)

---

### ğŸ“Œ Semaine 6 â€“ PyTorch Fundamentals
- ğŸ”— Cours : [PyTorch Beginner](https://pytorch.org/tutorials/beginner/nn_tutorial.html)
- ğŸ§ª Projet : entraÃ®nement dâ€™un MLP sur MNIST (avec batching, loss, opt)

---

### ğŸ“Œ Semaine 7 â€“ CNN + GPU
- ğŸ”— Cours : [Fastbook Chapitres 1â€“5](https://course.fast.ai)
- ğŸ§ª Projet : classification dâ€™images avec CNN (dataset CIFAR-10 ou MNIST)

---

### ğŸ“Œ Semaine 8 â€“ Packaging modÃ¨le & API
- ğŸ§ª Projet : modÃ¨le PyTorch exposÃ© via FastAPI
- Dockerise lâ€™API pour une dÃ©mo locale ou sur Hugging Face Spaces

---

## ğŸ—“ï¸ Mois 3 â€” NLP Moderne & Transformers

### ğŸ“Œ Semaine 9 â€“ NLP Classique + Embeddings
- ğŸ”— Cours : [Hugging Face NLP Chap 1â€“3](https://huggingface.co/learn/nlp-course/chapter1)
- ğŸ§ª Projet : classification de sentiments Twitter avec `TF-IDF + LogisticRegression`

---

### ğŸ“Œ Semaine 10 â€“ Transformers (Hugging Face)
- ğŸ”— Cours : Hugging Face chapitres 4â€“6
- ğŸ§ª Projet : QA ou text-generation avec `pipeline()` et `AutoModelFor...`

---

### ğŸ“Œ Semaine 11 â€“ Fine-tuning de modÃ¨le prÃ©-entraÃ®nÃ©
- ğŸ”— Guide : [Fine-tuning avec Trainer HF](https://huggingface.co/learn/nlp-course/chapter3)
- ğŸ§ª Projet : fine-tuner BERT sur un dataset custom (IMDb, tweet sentiment, etc.)

---

### ğŸ“Œ Semaine 12 â€“ Projet final + DÃ©ploiement
- ğŸ§ª Projet final :
  - Dataset rÃ©el
  - EntraÃ®nement (ML ou DL)
  - DÃ©ploiement (FastAPI + Docker)
  - Optionnel : Streamlit ou Gradio en front

---

## ğŸ”§ Stack Tech et Concepts Ã  MaÃ®triser
- `numpy`, `pandas`, `matplotlib`, `scikit-learn`
- `PyTorch`, `torchvision`, `transformers`
- `FastAPI`, `Docker`, `Jupyter`, `conda`
- Tensors, gradient descent, batching, fine-tuning

---

## ğŸ’¡ Bonus Ressources
- ğŸ“š [Python Data Science Handbook (Jake VanderPlas)](https://jakevdp.github.io/PythonDataScienceHandbook/)
- ğŸ“š [FastAI](https://course.fast.ai/)
- ğŸ“š [Hugging Face NLP Course](https://huggingface.co/learn/nlp-course)
- ğŸ§ª [PapersWithCode](https://paperswithcode.com)
- ğŸŒ [Hugging Face Spaces](https://huggingface.co/spaces)