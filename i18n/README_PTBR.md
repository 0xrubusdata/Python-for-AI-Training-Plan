<div align="center">
  <img src="../docs/ptbr.jpg" alt="Tugal" width="25%" />
</div>

---

# ğŸ§  Plano â€” AvanÃ§ando para o NÃ­vel de IA com Python

> ğŸ¯ Objetivo: Dominar machine learning, deep learning e modelos transformers em Python, com projetos prÃ¡ticos e implantaÃ§Ã£o.

---

## ğŸ—“ï¸ MÃªs 1 â€” Fundamentos de IA + Dados com Python

### ğŸ“Œ Semana 1 â€“ Python IA & Numpy
- ğŸ”— Cursos: [Kaggle Python](https://www.kaggle.com/learn/python) + [Kaggle Numpy](https://www.kaggle.com/learn/numpy)
- âš™ï¸ ConfiguraÃ§Ã£o: Instalar **Miniconda**, criar um ambiente `ia`
- ğŸ§ª Projeto: Script de anÃ¡lise de matrizes (mÃ©dia, mediana, desvio padrÃ£o, etc.)

---

### ğŸ“Œ Semana 2 â€“ Pandas & VisualizaÃ§Ã£o
- ğŸ”— Cursos: [Kaggle Pandas](https://www.kaggle.com/learn/pandas), [Kaggle VisualizaÃ§Ã£o de Dados](https://www.kaggle.com/learn/data-visualization)
- ğŸ§ª Projeto: AnÃ¡lise exploratÃ³ria dos dados (EDA) do conjunto Titanic

---

### ğŸ“Œ Semana 3 â€“ Machine Learning com Scikit-learn
- ğŸ”— Cursos: [IntroduÃ§Ã£o ao Machine Learning â€“ Kaggle](https://www.kaggle.com/learn/intro-to-machine-learning)
- ğŸ§ª Projeto: PrevisÃ£o de preÃ§os de imÃ³veis ou classificaÃ§Ã£o de emails (spam/ham)

---

### ğŸ“Œ Semana 4 â€“ Jupyter + Projeto de OrganizaÃ§Ã£o
- ğŸ§ª Objetivo: Dominar Jupyter, organizar cÃ³digo em arquivos `.py`, criar a estrutura de um projeto de ML
- BÃ´nus: Inicializar `wandb` ou `mlflow` para rastreamento de experimentos

---

## ğŸ—“ï¸ MÃªs 2 â€” Deep Learning com PyTorch

### ğŸ“Œ Semana 5 â€“ Fundamentos de Deep Learning
- ğŸ”— Cursos: [Deep Learning â€“ Kaggle](https://www.kaggle.com/learn/deep-learning)
- ğŸ§ª Projeto: Rede neural "do zero" em `numpy` (regressÃ£o XOR)

---

### ğŸ“Œ Semana 6 â€“ Fundamentos do PyTorch
- ğŸ”— Cursos: [PyTorch para Iniciantes](https://pytorch.org/tutorials/beginner/nn_tutorial.html)
- ğŸ§ª Projeto: Treinar um MLP no MNIST (com batching, funÃ§Ã£o de perda, otimizador)

---

### ğŸ“Œ Semana 7 â€“ CNN + GPU
- ğŸ”— Cursos: [Fastbook CapÃ­tulos 1â€“5](https://Coursese.fast.ai)
- ğŸ§ª Projeto: ClassificaÃ§Ã£o de imagens com CNN (conjunto CIFAR-10 ou MNIST)

---

### ğŸ“Œ Semana 8 â€“ Empacotamento do Modelo & API
- ğŸ§ª Projeto: Modelo PyTorch exposto via FastAPI
- Dockerizar a API para demo local ou via Hugging Face Spaces

---

## ğŸ—“ï¸ MÃªs 3 â€” NLP ClÃ¡ssico + Embeddings

### ğŸ“Œ Semana 9 â€“ NLP ClÃ¡ssico + Embeddings
- ğŸ”— Cursos: [Hugging Face NLP Cap 1â€“3](https://huggingface.co/learn/nlp-Coursese/chapter1)
- ğŸ§ª Projeto: ClassificaÃ§Ã£o de sentimentos no Twitter com `TF-IDF + LogisticRegression`

---

### ğŸ“Œ Semana 10 â€“ Transformers (Hugging Face)
- ğŸ”— Cursos: Hugging Face capÃ­tulos 4â€“6
- ğŸ§ª Projeto: QA ou geraÃ§Ã£o de texto com `pipeline()` e `AutoModelFor...`

---

### ğŸ“Œ Semana 11 â€“ Fine-tuning de Modelos PrÃ©-treinados
- ğŸ”— Guia: [Fine-tuning com Trainer da HF](https://huggingface.co/learn/nlp-Coursese/chapter3)
- ğŸ§ª Projeto: Fine-tune do BERT em um dataset customizado (IMDb, sentimento em tweets, etc.)

---

### ğŸ“Œ Semana 12 â€“ Projeto Final + ImplantaÃ§Ã£o
- ğŸ§ª Projeto Final:
  - Dataset do mundo real
  - Treinamento (ML ou DL)
  - ImplantaÃ§Ã£o (FastAPI + Docker)
  - Opcional: Frontend com Streamlit ou Gradio

---

## ğŸ”§ Stack TecnolÃ³gica e Conceitos para Dominar
- `numpy`, `pandas`, `matplotlib`, `scikit-learn`
- `PyTorch`, `torchvision`, `transformers`
- `FastAPI`, `Docker`, `Jupyter`, `conda`
- Tensores, descida do gradiente, batching, fine-tuning

---

## ğŸ’¡ Recursos Extras
- ğŸ“š [Python Data Science Handbook (Jake VanderPlas)](https://jakevdp.github.io/PythonDataScienceHandbook/)
- ğŸ“š [FastAI](https://Coursese.fast.ai/)
- ğŸ“š [Curso NLP da Hugging Face](https://huggingface.co/learn/nlp-Coursese)
- ğŸ§ª [PapersWithCode](https://paperswithcode.com)
- ğŸŒ [Hugging Face Spaces](https://huggingface.co/spaces)
